# LLM 화학식 Generator — 검토 및 보류 결정

> **상태: 보류 (2026-02-28)**
> **결론: 안 만든다. 단, 생각이 바뀔 수 있으므로 기록 보존.**

---

## 발단: 아이디어

프롬프트를 화학식처럼 조합하는 8번째 Generator.

기존 7개 Generator가 **원소**라면, Chemistry는 **반응식 설계기**.

```
prompts/chemistry/
├── index.html
└── chemistry-generator.html
```

| | Generator (기존 7개) | Chemistry (제안) |
|---|---|---|
| **실행 환경** | 브라우저 | 서버 / Termux |
| **기술** | HTML + 바닐라 JS | Python + API |
| **입력** | 유저가 변수 선택 | 레시피 (YAML/JSON) |
| **출력** | 복사할 프롬프트 텍스트 | LLM이 실제로 실행한 결과 |
| **비용** | 무료 | API 토큰 비용 발생 |

레시피 예시:

```yaml
name: "코드 리뷰 화학식"
steps:
  - id: generate
    llm: claude-sonnet
    prompt: "이 요구사항으로 코드 작성: {input}"
  - id: review
    llm: gpt-4o
    prompt: "이 코드 리뷰해: {generate.output}"
  - id: synthesize
    llm: claude-opus
    prompt: |
      원본: {generate.output}
      리뷰: {review.output}
      종합해서 최종 코드 작성
```

---

## 보류 사유

### 1. 자동 체이닝은 사람의 판단을 빼먹는다

| 자동 체이닝 (LangChain류) | 수동 크로스 LLM (현재 방식) |
|---|---|
| 중간 결과를 안 본다 | **중간에 보고 방향을 튼다** |
| 파이프가 고정되어 있다 | **맥락에 따라 다른 LLM에 던진다** |
| "아 이거 아닌데" 할 때 이미 끝까지 갔다 | **아닌 순간 멈춘다** |
| 토큰만 태운다 | **사고한다** |

> 온톨로지처럼 의사결정 시점에서만 중요하지,
> 프로세스화 시켜서 자동으로 답을 내봤자 뭔 대단한 파인딩이 나오느냐.
> 결국 유저의 개입과 결정이 있어야 정리되는 거다.

### 2. 똑똑한 LLM 하나면 충분하다

Claude Opus 하나한테 "코드 짜고 리뷰하고 종합해"라고 하면 3단계 체인이랑 비슷한 결과.
오히려 컨텍스트가 끊기지 않으니까 **단일 LLM이 더 나을 수 있다.**

멀티 LLM이 의미 있는 경우는 딱 하나 — 서로 다른 모델이 **진짜 다른 관점**을 줄 때.
근데 그건 이미 수동으로 하고 있고, 뭘 취하고 버릴지 결정하는 건 **사람 머리**다.

### 3. 캐릭터 대사 같은 창작 용도는 RAG + 파인튜닝이 답

웹툰/소설 캐릭터 대사를 만들 때 LLM 체이닝보다
**내 말투와 습성을 패턴화한 파인튜닝 모델**이 더 낫다.

이건 이미 Dataset Generator가 커버하는 영역:

```
대화 로그 → Dataset Generator → JSONL → 파인튜닝 → 내 말투 모델
```

---

## 재검토 트리거

다음 상황이 오면 다시 꺼내본다:

- [ ] API 비용이 무시할 수준으로 떨어질 때
- [ ] 수동 크로스 LLM 작업이 주 5회 이상으로 늘어날 때
- [ ] 반복되는 체이닝 패턴이 3개 이상 식별될 때
- [ ] 자동화해도 중간 판단이 필요 없는 파이프라인이 발견될 때

---

## 서사 분류

```
커밋 유형: 검토 → 보류
서사: 전환 — 만들려다가 "이거 아닌데" 하고 멈춘 지점
의미: 자동화의 유혹을 이기고 본질(사람의 판단)을 지킨 순간
```
